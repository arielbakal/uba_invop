{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzQFAeEYBx6U"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import minimize_scalar\n",
        "from sklearn.datasets import make_blobs\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El presente trabajo pr√°ctico aborda el problema de Fermat-Weber, que consiste en encontrar la ubicaci√≥n √≥ptima de un √∫nico punto que minimice la suma de las distancias ponderadas a un conjunto de ubicaciones dadas en el plano. Cada una de estas ubicaciones tiene un peso asociado, que representa su importancia relativa dentro del problema.\n",
        "\n",
        "Este tipo de modelo tiene m√∫ltiples aplicaciones pr√°cticas en problemas de localizaci√≥n, log√≠stica y planificaci√≥n, y en este caso se enmarca en la decisi√≥n de instalar un centro de atenci√≥n m√©dica temporal en un √°rea afectada.\n",
        "\n",
        "El objetivo del trabajo es comparar distintas estrategias de resoluci√≥n para este problema, analizando su desempe√±o frente a diferentes configuraciones de puntos y pesos. Para ello, se implementaron tres m√©todos de optimizaci√≥n:\n",
        "\n",
        "* Algoritmo de Weiszfeld (original y modificado),\n",
        "\n",
        "\n",
        "* Descenso coordenado, y\n",
        "\n",
        "* Direcci√≥n de descenso con subgradientes.\n",
        "\n",
        "Se probaron estos m√©todos sobre varias instancias con caracter√≠sticas variadas, evaluando su tiempo de ejecuci√≥n, estabilidad y n√∫mero de iteraciones hasta converger. A continuaci√≥n, se detallan las implementaciones y resultados obtenidos.\n",
        "\n"
      ],
      "metadata": {
        "id": "U3TK7iuIOlwm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2JzTYKzOLzW"
      },
      "source": [
        "## Algoritmo de Weiszfeld"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3I-miMR1Ngpg"
      },
      "outputs": [],
      "source": [
        "def weiszfeld(p, w, x0, tol=1e-5, iter_max=1000):\n",
        "  start = time.time()\n",
        "  x_actual = x0\n",
        "\n",
        "  iteraciones = 0\n",
        "  while iteraciones < iter_max:\n",
        "    distancias = []\n",
        "    for i in range(len(p)):\n",
        "      distancia = np.linalg.norm(x_actual - p[i])\n",
        "      if distancia < 1e-12: # x = p\n",
        "        x_sig = p[i]\n",
        "        return x_sig, iteraciones, time.time() - start\n",
        "      distancias.append(np.linalg.norm(x_actual - p[i]))\n",
        "\n",
        "    numerador = sum((w[i] * p[i]) / distancias[i] for i in range(len(p)))\n",
        "    denominador = sum(w[i] / distancias[i] for i in range(len(p)))\n",
        "    x_sig = numerador / denominador\n",
        "\n",
        "    if np.linalg.norm(x_sig - x_actual) < tol:\n",
        "      return x_sig, iteraciones, time.time() - start\n",
        "\n",
        "    x_actual = x_sig\n",
        "    iteraciones += 1\n",
        "\n",
        "  return x_sig, iteraciones, time.time() - start"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def weiszfeld_modificado(p, w, x0, tol=1e-6, max_iter=1000, eps=1e-12):\n",
        "    p = np.asarray(p, dtype=float)\n",
        "    m, _ = p.shape\n",
        "\n",
        "    x = x0 # centroide ponderado\n",
        "    start = time.perf_counter()\n",
        "\n",
        "    for k in range(max_iter):\n",
        "        dist = np.linalg.norm(p - x, axis=1)\n",
        "\n",
        "        # verifico singularidad, ie, si x es igual a algun p_j\n",
        "        j = np.argmin(dist)\n",
        "        if dist[j] < eps:\n",
        "            inds_i = np.arange(m) != j # indices de los puntos distintos de j\n",
        "            diff_j = p[inds_i] - p[j]           # pi - pj\n",
        "            dist_j = np.linalg.norm(diff_j, axis=1)\n",
        "\n",
        "            # R_j = suma_{i‚â†j} w_i (p_j - p_i)/||p_j - p_i||\n",
        "            R = (w[inds_i][:, None] * (-diff_j / dist_j[:, None])).sum(axis=0)\n",
        "            norm_R = np.linalg.norm(R)\n",
        "\n",
        "            if norm_R <= w[j]:  # optimo alcanzado\n",
        "                return p[j], k, time.perf_counter() - start\n",
        "\n",
        "            # paso correctivo S(p_j)\n",
        "            d_j = -R / norm_R                 # direccion de descenso normalizada\n",
        "            denom = (w[inds_i] / dist_j).sum()  # suma__{i‚â†j} w_i / ||pi - pj||\n",
        "            t_j = (norm_R - w[j]) / denom     # longitud del paso\n",
        "            x_next = p[j] + d_j * t_j\n",
        "        else:\n",
        "            # paso estandar de Weiszfeld\n",
        "            inv_dist = w / dist\n",
        "            x_next = (inv_dist[:, None] * p).sum(axis=0) / inv_dist.sum()\n",
        "\n",
        "        if np.linalg.norm(x_next - x) < tol:\n",
        "            return x_next, k + 1, time.perf_counter() - start\n",
        "\n",
        "        x = x_next\n",
        "\n",
        "    return x, max_iter, time.perf_counter() - start"
      ],
      "metadata": {
        "id": "m8-AL8Cu4Sr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El algoritmo de Weiszfeld busca el **punto fijo** de la funci√≥n  \n",
        "$\n",
        "T(x)\\;=\\;\\frac{\\sum_{i=1}^n \\tfrac{w_i\\,p_i}{\\|x - p_i\\|}}{\\sum_{i=1}^n \\tfrac{w_i}{\\|x - p_i\\|}}\n",
        "$\n",
        "\n",
        "partiendo de una estimaci√≥n inicial $x^{(0)}\\notin P$ (en nuestro caso el centroide ponderado).\n",
        "\n",
        "Buscamos este punto fijo porque T(x) es equivalente a las condiciones de optimalidad $\\nabla f(x)=0\\$ de nuestro problema con\n",
        "\n",
        "$\n",
        "f(x)=\\sum_{i=1}^n w_i \\,\\|x - p_i\\|.\n",
        "$\n",
        "\n",
        "Un punto fijo $x^{*}$ cumple esta condici√≥n, lo que nos garantiza que sea un punto estacionario, o bien un minimo global (por ser f convexa).\n",
        "\n",
        "En cada iteraci√≥n k, calculamos  \n",
        "$\n",
        "x^{(k+1)}\n",
        "\\;=\\;\n",
        "\\frac{\\displaystyle\\sum_{i=1}^n \\frac{w_i\\,p_i}{\\big\\|x^{(k)} - p_i\\big\\|}}\n",
        "     {\\displaystyle\\sum_{i=1}^n \\frac{w_i}{\\big\\|x^{(k)} - p_i\\big\\|}}\n",
        "$\n",
        "\n",
        "hasta que $\\|x^{(k+1)} - x^{(k)}\\|$ sea menor que alguna tolerancia (1-e5 en nuestro caso).\n",
        "De esta manera cada $x^{(k+1)}$ es un **promedio ponderado inverso** de las posiciones $p_i$, donde los pesos din√°micos son $w_i / \\|x^{(k)}-p_i\\|$.\n",
        "\n",
        "Este algoritmo es un metodo **ad hoc** para este problema ya que se deriva directamente de las condiciones de optimalidad del problema de minimzar $\\sum_{i=1}^n w_i\\,\\|x - p_i\\|$ y no aplicamos un esquema generico de optimizaci√≥n (como por ej. el gradiente), sino que reponderamos cada distancia $\\|x-p_i\\|$ usando los terminos $\n",
        "\\frac{w_i}{\\|x - p_i\\|}\n",
        "$ que aparecen al diferenciar la suma de distancias.  "
      ],
      "metadata": {
        "id": "ZjFTGPNYNdJ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decidimos utilizar la modificaci√≥n 1 del algoritmo de Weiszfeld (presentada en clase).\n",
        "\n",
        "En esta modificaci√≥n, verificamos singularidad (la iteraci√≥n coincide con un punto $p_j$) al inicio y calculamos el vector\n",
        "\n",
        "$\n",
        "R \\;=\\;\\sum_{i\\neq j} w_i\\,\\frac{p_j - p_i}{\\|p_j - p_i\\|}\n",
        "$\n",
        "\n",
        "y luego si $\\|R\\|>w_j$, realizamos un paso correctivo\n",
        "\n",
        "$\n",
        "x^{(k+1)}\n",
        "= S(p_j)\n",
        "= p_j \\;-\\; \\frac{R}{\\|R\\|}\\,\n",
        "  \\frac{\\|R\\| - w_j}{\\sum_{i\\neq j} \\tfrac{w_i}{\\|p_j - p_i\\|}}.\n",
        "$\n",
        "\n",
        "Caso contrario, utilizamos el paso estandar de Weiszfeld.\n",
        "\n",
        "Esta modificacion evita la indefinicion y las oscilaciones cerca de los puntos $p_j$, nos garantiza una disminucion monotona de la funcion objetivo aun en caso de singularidad y al hacer un desplazamiento optimo en el entorno de un punto $p_j$, mejoramos la velocidad de convergencia."
      ],
      "metadata": {
        "id": "gX4gr9fyUhgq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlpGKxZSAKCU"
      },
      "source": [
        "## M√©todo de descenso coordenado\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wb0vvjF-AKCV"
      },
      "outputs": [],
      "source": [
        "def f(x, puntos, pesos):\n",
        "    total = 0.0\n",
        "    for i in range(len(puntos)):\n",
        "        p = puntos[i]         # punto i\n",
        "        w = pesos[i]          # peso i\n",
        "        distancia = np.linalg.norm(x - p)  # distancia eucl√≠dea ||x - p_i||\n",
        "        total += w * distancia            # suma ponderada\n",
        "    return total\n",
        "\n",
        "def descenso_coordenado(puntos, pesos, x0, tol=1e-5, max_iter=1000):\n",
        "    x = np.array(x0, dtype=float)\n",
        "    n = len(x)                     # Cantidad de coordenadas\n",
        "    iter = 0\n",
        "    start = time.time()\n",
        "    for k in range(max_iter):\n",
        "        k += 1\n",
        "        x_anterior = x.copy()     # Guardamos x actual para comparar\n",
        "\n",
        "        # Recorremos cada coordenada (0 para x, 1 para y)\n",
        "        for i in range(n):\n",
        "            def f_univar(lambd):\n",
        "                x_temp = x.copy()\n",
        "                x_temp[i] += lambd  # Solo cambiamos la coordenada i\n",
        "                return f(x_temp, puntos, pesos)\n",
        "\n",
        "            resultado = minimize_scalar(f_univar)  # Minimiza en Œª ‚àà ‚Ñù\n",
        "            paso = resultado.x\n",
        "            x[i] += paso  # Actualiza la coordenada i\n",
        "\n",
        "        # Criterio de parada: si el cambio es peque√±o, terminamos\n",
        "        if np.linalg.norm(x - x_anterior) < tol:\n",
        "            break\n",
        "\n",
        "    return x, k, time.time() - start"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "En el c√≥digo, la funci√≥n f calcula la suma ponderada de distancias eucl√≠deas entre un punto candidato ùë• y un conjunto de puntos dados. Para cada punto, se mide su distancia a ùë•, se multiplica por su peso y se acumulan estos valores para obtener el resultado total.\n",
        "\n",
        "Para resolver el problema se utiliza el m√©todo de descenso coordenado, un algoritmo iterativo que actualiza una coordenada a la vez. En cada iteraci√≥n, se minimiza la funci√≥n variando √∫nicamente la coordenada seleccionada mientras las dem√°s se mantienen fijas, recorriendo las coordenadas de forma **c√≠clica**. Para ello, se define una funci√≥n univariante que depende solo de la coordenada actual, y se emplea la funci√≥n minimize_scalar de SciPy para encontrar el valor √≥ptimo en esa direcci√≥n. Posteriormente, se actualiza la coordenada con este valor y se contin√∫a con la siguiente.\n",
        "\n",
        "El **criterio de parada** se basa en la magnitud del cambio entre la soluci√≥n actual y la anterior: cuando la norma de la diferencia entre ambos puntos es menor que una tolerancia preestablecida, se considera que el algoritmo ha convergido y se detiene. En caso contrario, el proceso contin√∫a hasta alcanzar un m√°ximo de iteraciones definidas.\n",
        "\n",
        "Este m√©todo es adecuado para funciones convexas como la que plantea el problema de Fermat-Weber, y presenta la **ventaja** de no requerir el c√°lculo expl√≠cito de derivadas, lo cual es relevante ya que la funci√≥n no es diferenciable en los puntos donde la soluci√≥n coincide con alguno de los puntos dados.\n",
        "\n"
      ],
      "metadata": {
        "id": "UPrvGWO6AKCW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiHD5Ak-dx5d"
      },
      "source": [
        "## Algoritmo de Direcci√≥n de Descenso (utilizando el subgradiente de la funci√≥n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovkt67Y3ds59"
      },
      "outputs": [],
      "source": [
        "#IMPLEMENTACI√ìN COMO EN EL CODIGO\n",
        "#SE UTILIZ√ì EL M√âTODO DE SUBGRADIENTE COMO PASO DE DECISI√ìN\n",
        "def f(x, puntos, pesos):\n",
        "    total = 0.0\n",
        "    for i in range(len(puntos)):\n",
        "        p = puntos[i]         # punto i\n",
        "        w = pesos[i]          # peso i\n",
        "        distancia = np.linalg.norm(x - p)  # distancia eucl√≠dea ||x - p_i||\n",
        "        total += w * distancia            # suma ponderada\n",
        "    return total\n",
        "\n",
        "def direccion_de_descenso(p, w,x0,tol=1e-5, max_iter=1000):\n",
        "    start = time.time()\n",
        "    k = 0\n",
        "    c1 = 0.5\n",
        "    x_k = x0.copy()\n",
        "    while (k < max_iter):\n",
        "        subgradiente_k = np.zeros_like(x0)\n",
        "        for i in range(len(p)):\n",
        "            distancia = np.linalg.norm(x_k - p[i])\n",
        "            if distancia > 0:\n",
        "                subgradiente_k += w[i] * ((x_k - p[i])/distancia)\n",
        "        if np.linalg.norm(subgradiente_k) < tol:\n",
        "            break\n",
        "        f_k = f(x_k,p,w)\n",
        "        a_k = 1\n",
        "\n",
        "        while (f(x_k - a_k*subgradiente_k, p ,w) > f_k - c1*a_k*np.dot(subgradiente_k, subgradiente_k)):\n",
        "            a_k = a_k * 0.5\n",
        "\n",
        "        x_k = x_k - a_k * subgradiente_k\n",
        "        k = k+1\n",
        "    return x_k, k, time.time() - start"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para este algoritmo se utiliz√≥ la misma funci√≥n f que para el algoritmo de descenso coordinado. Decidimos utilizar el subgradiente de la funci√≥n como paso de decisi√≥n, ya que en ciertos casos el gradiente se pod√≠a indefinir. Esto ocurre en los casos (x_k = pi).\n",
        "\n",
        "El c√≥digo del algoritmo sigue el pseudoc√≥digo gen√©rico para estos algoritmos. Este m√©todo es iterativo; busca minimizar la funci√≥n f, y en cada iteraci√≥n vuelve a calcular y utilizar el subgradiente, ya que este muestra una direcci√≥n en la que f no aumenta. Una vez tomada esta, se actualizan los valores y sigue iterando. Se utiliz√≥ el criterio de armijo (en el √∫ltimo while), que busca asegurar que en cada iteraci√≥n se disminuya lo suficiente la funci√≥n.\n",
        "\n",
        "Mientras no se cumpla el criterio de parada o se llegue a la cantidad m√°xima de iteraciones fijadas el programa continua iterando. A prop√≥sito de esto, el criterio de parada para este algoritmo es que el subgradiente llegue a un valor menor al prefijado (llamado tol en el c√≥digo).\n",
        "\n",
        "Este algoritmo en general logra minimizar f en una buena medida. Adem√°s tiene la ventaja de que funciona con funciones no diferenciables. Sin embargo, su velocidad de convergencia no es una virtud; a√∫n m√°s, dadas ciertas instancias puede llegar a requerir muchas iteraciones y consecuentemente tardar m√°s que otros algoritmos. Es un m√©todo √∫til cuando la funci√≥n no es diferenciable (ya que resuelve el problema del gradiente indefinido), pero si esta s√≠ fuera diferenciable, en general conviene utilizar como paso de decisi√≥n el gradiente simplemente."
      ],
      "metadata": {
        "id": "4CIXHMnwAz-V"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLaV-r3-LFwO"
      },
      "source": [
        "## Instancias de prueba\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para evaluar el desempe√±o de los algoritmos implementados se dise√±aron seis instancias de prueba con caracter√≠sticas diversas. Estas instancias buscan representar distintos escenarios que podr√≠an surgir en aplicaciones reales del problema de Fermat-Weber, incluyendo situaciones con cl√∫steres, outliers, pesos desbalanceados y espacios de alta dimensi√≥n.\n",
        "\n",
        "La **primera instancia** presenta tres cl√∫steres bien separados entre s√≠, lo que obliga al algoritmo a encontrar un punto de compromiso que minimice la distancia ponderada a todos ellos. Se espera que la soluci√≥n se ubique cerca del centro ponderado entre los grupos.\n",
        "\n",
        "La **segunda instancia** distribuye puntos de forma aproximadamente uniforme en el plano, buscando simular una cobertura amplia y homog√©nea del √°rea afectada. En este caso, la soluci√≥n √≥ptima deber√≠a coincidir con el centro geom√©trico de la distribuci√≥n de los puntos.\n",
        "\n",
        "La **tercera instancia** introduce un √∫nico punto con un peso muy elevado, en comparaci√≥n con otros puntos livianos distribuidos aleatoriamente. Este escenario simula la presencia de una ubicaci√≥n con alt√≠sima prioridad m√©dica, y se espera que el centro √≥ptimo se sit√∫e muy pr√≥ximo a ese punto, ya que es \"el mas importante\".\n",
        "\n",
        "La **cuarta instancia** combina un grupo de puntos relativamente agrupados con un outlier lejano, pero con el mismo peso. Este caso permite observar c√≥mo los m√©todos responden ante valores extremos: la soluci√≥n no deber√≠a quedar ni en el centroide del grupo ni en el outlier, sino en una posici√≥n intermedia.\n",
        "\n",
        "La **quinta instancia** contiene puntos alineados en una l√≠nea horizontal con diferentes pesos, lo cual permite evaluar el comportamiento de los m√©todos cuando la soluci√≥n debe desplazarse a lo largo de una √∫nica direcci√≥n influenciada por los pesos asignados.\n",
        "\n",
        "Finalmente, la **sexta instancia** busca probar qu√© tan bien funcionan los m√©todos cuando se trabaja con muchos datos y en un espacio m√°s complejo. Para eso, se generaron 20.000 puntos al azar en un espacio de cinco dimensiones. Este tipo de prueba sirve para ver si los algoritmos son eficientes y r√°pidos tambi√©n cuando el problema se vuelve m√°s grande y dif√≠cil de visualizar."
      ],
      "metadata": {
        "id": "YFHLjRkNLXTW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eK_sM06LFwP"
      },
      "source": [
        "üîπ Instancia 1: M√∫ltiples cl√∫steres separados\n",
        "\n",
        "Tres grupos bien definidos en el plano. Se espera que el centro est√© en una posici√≥n de compromiso entre los cl√∫steres.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instancias = []"
      ],
      "metadata": {
        "id": "hgWx78bhRmnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clusters_separados(n_samples, centers, std, box):\n",
        "    X, y = make_blobs(\n",
        "        n_samples=n_samples,\n",
        "        centers=centers,\n",
        "        cluster_std=std,\n",
        "        center_box=box,\n",
        "        random_state=42\n",
        "    )\n",
        "    return X\n",
        "\n",
        "pts_clusters = clusters_separados(16000, centers=16, std=5.0, box=(-4000,4000))\n",
        "pesos_clusters = np.random.rand(16000)\n",
        "instancia_clusters = pts_clusters, pesos_clusters\n",
        "instancias.append(instancia_clusters)"
      ],
      "metadata": {
        "id": "PSZ3RUHmLFwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfj4eONtLFwQ"
      },
      "source": [
        "üîπ Instancia 2: Puntos bien dispersos.\n",
        "\n",
        "La soluci√≥n deber√≠a estar en el centro geom√©trico.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dispersos_uniforme(n_samples, xlim, ylim):\n",
        "    xs = np.random.uniform(xlim[0], xlim[1], size=n_samples)\n",
        "    ys = np.random.uniform(ylim[0], ylim[1], size=n_samples)\n",
        "    return np.column_stack((xs, ys))\n",
        "\n",
        "pts_dispersos = dispersos_uniforme(16000, (-4000,4000), (-4000,4000))\n",
        "pesos_dispersos = np.random.rand(16000)\n",
        "instancia_dispersos = pts_dispersos, pesos_dispersos\n",
        "instancias.append(instancia_dispersos)"
      ],
      "metadata": {
        "id": "_isIQ4JjLFwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loCJo-XALFwS"
      },
      "source": [
        "üîπ Instancia 3: Un punto muy pesado entre puntos livianos\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def punto_pesado(base_pts, base_weights, heavy_weight):\n",
        "    pts = base_pts.copy()\n",
        "    w = base_weights.copy()\n",
        "    center = np.mean(base_pts, axis=0)\n",
        "    pts = np.vstack([pts, center])\n",
        "    w = np.concatenate([w, [heavy_weight]])\n",
        "    return pts, w\n",
        "\n",
        "# 19999 puntos liviano + 1 con peso = 20000\n",
        "w_base = np.ones(19999)\n",
        "pts_base = dispersos_uniforme(19999, (0,100), (0,100))\n",
        "pts_pesados, weights_pesados = punto_pesado(pts_base, w_base, heavy_weight=1000)\n",
        "instancia_pesados = pts_pesados, weights_pesados\n",
        "instancias.append(instancia_pesados)"
      ],
      "metadata": {
        "id": "3YYKJXWdLFwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kk2lfhiWLFwU"
      },
      "source": [
        "üîπ Instancia 4: Un outlier lejano con el mismo peso\n",
        "\n",
        "Cuatro puntos agrupados cerca del origen y un outlier. Se espera que la soluci√≥n se desplace hacia el outlier, aunque no totalmente.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def outlier_lejano(base_pts, base_weights, outlier_coord):\n",
        "    pts = np.vstack([base_pts, outlier_coord])\n",
        "    w = np.concatenate([base_weights, [base_weights.mean()]])\n",
        "    return pts, w\n",
        "\n",
        "pts_outlier, weights_outlier = outlier_lejano(pts_dispersos, np.ones(len(pts_dispersos)), (10000,10000))\n",
        "instancia_outlier = pts_outlier, weights_outlier\n",
        "instancias.append(instancia_outlier)"
      ],
      "metadata": {
        "id": "44cd4DtBLFwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBg6fNKcLFwV"
      },
      "source": [
        "\n",
        "üîπ Instancia 5: Puntos alineados con pesos distintos\n",
        "\n",
        "Todos los puntos est√°n en la misma l√≠nea horizontal. La soluci√≥n deber√≠a estar m√°s cerca del punto que tiene peso mayor."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def alineados_pesos(n_samples, xlim):\n",
        "    xs = np.linspace(xlim[0], xlim[1], n_samples)\n",
        "    pts = np.column_stack((xs, np.zeros(n_samples)))\n",
        "    w = np.random.randint(1, 10, size=n_samples)\n",
        "    return pts, w\n",
        "\n",
        "pts_linea, weights_linea = alineados_pesos(20000, (0,10000))\n",
        "instancia_linea = pts_linea, weights_linea\n",
        "instancias.append(instancia_linea)"
      ],
      "metadata": {
        "id": "Wf5u_mDJLFwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msKHWZypLFwW"
      },
      "source": [
        "üîπ Instancia 6: Puntos random en $R^{5}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tljOPHMlLFwW"
      },
      "outputs": [],
      "source": [
        "n = 20000\n",
        "puntos_6 = np.random.rand(n, 5)\n",
        "pesos_6 = np.random.rand(n)\n",
        "instancia_6 = puntos_6, pesos_6\n",
        "instancias.append(instancia_6)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluacion de las instancias:"
      ],
      "metadata": {
        "id": "g_e0GBlkLKY4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MyCcfYs_ZNC",
        "outputId": "59aa92aa-f4a8-4a89-8df6-0317992bbfb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##### Instancia 1 #####\n",
            "\n",
            "WEISZFELD: [-983.15508966 -564.8287985 ] en 6.5003s (31 iteraciones)\n",
            "WEISZFELD MODIFICADO: [-983.15508633 -564.82880676] en 0.0382s (36 iteraciones)\n",
            "DESCENSO COORDENADO: [-983.15513055 -564.82865791] en 19.5100s (5 iteraciones)\n",
            "DIRECCION DE DESCENSO  [-983.15504816 -564.82890131] en 218.0915s (100 iteraciones)\n",
            "\n",
            "##### Instancia 2 #####\n",
            "\n",
            "WEISZFELD: [-5.28104312  5.20232842] en 4.7101s (20 iteraciones)\n",
            "WEISZFELD MODIFICADO: [-5.28104754  5.20232553] en 0.0252s (24 iteraciones)\n",
            "DESCENSO COORDENADO: [-5.28101126  5.20237055] en 13.6725s (3 iteraciones)\n",
            "DIRECCION DE DESCENSO  [-5.28102269  5.20234334] en 252.0964s (100 iteraciones)\n",
            "\n",
            "##### Instancia 3 #####\n",
            "\n",
            "WEISZFELD: [50.03814008 50.1564903 ] en 0.1303s (0 iteraciones)\n",
            "WEISZFELD MODIFICADO: [50.03814008 50.1564903 ] en 0.0030s (0 iteraciones)\n",
            "DESCENSO COORDENADO: [50.03814008 50.1564903 ] en 4.8612s (1 iteraciones)\n",
            "DIRECCION DE DESCENSO  [50.03814008 50.1564903 ] en 531.2828s (100 iteraciones)\n",
            "\n",
            "##### Instancia 4 #####\n",
            "\n",
            "WEISZFELD: [-15.81381698  24.57503436] en 3.5084s (20 iteraciones)\n",
            "WEISZFELD MODIFICADO: [-15.81382234  24.57503412] en 0.0259s (24 iteraciones)\n",
            "DESCENSO COORDENADO: [-15.81381023  24.57486742] en 20.3151s (4 iteraciones)\n",
            "DIRECCION DE DESCENSO  [-15.81384036  24.57502909] en 247.9203s (100 iteraciones)\n",
            "\n",
            "##### Instancia 5 #####\n",
            "\n",
            "WEISZFELD: [4960.74803686    0.        ] en 17.9941s (69 iteraciones)\n",
            "WEISZFELD MODIFICADO: [4960.74803736    0.        ] en 0.0899s (70 iteraciones)\n",
            "DESCENSO COORDENADO: [ 4.96074804e+03 -3.72847087e-09] en 11.4947s (2 iteraciones)\n",
            "DIRECCION DE DESCENSO  [4960.74803741    0.        ] en 395.8716s (100 iteraciones)\n",
            "\n",
            "##### Instancia 6 #####\n",
            "\n",
            "WEISZFELD: [0.50295288 0.50233487 0.50283066 0.50053289 0.49843425] en 0.8483s (3 iteraciones)\n",
            "WEISZFELD MODIFICADO: [0.50295385 0.5023356  0.50283236 0.50053266 0.49843396] en 0.0132s (6 iteraciones)\n",
            "DESCENSO COORDENADO: [0.50295388 0.50233565 0.50283239 0.50053263 0.49843395] en 20.8391s (2 iteraciones)\n",
            "DIRECCION DE DESCENSO  [0.50295388 0.50233562 0.50283241 0.50053265 0.49843395] en 383.9023s (100 iteraciones)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(6):\n",
        "  print(f\"##### Instancia {i+1} #####\\n\")\n",
        "  points = instancias[i][0]\n",
        "  weights = instancias[i][1]\n",
        "  x_inicial = sum(weights[i]*points[i] for i in range(len(points))) / sum(weights[i] for i in range(len(points))) # centroide ponderado\n",
        "  sol_w, iter_w, time_w = weiszfeld(points, weights, x_inicial)\n",
        "  print(\"WEISZFELD:\", sol_w, f\"en {time_w:.4f}s\", f\"({iter_w} iteraciones)\")\n",
        "  sol_wm, iter_wm, time_wm = weiszfeld_modificado(points, weights, x_inicial)\n",
        "  print(\"WEISZFELD MODIFICADO:\", sol_wm, f\"en {time_wm:.4f}s\", f\"({iter_wm} iteraciones)\")\n",
        "  sol_c, iter_c, time_c = descenso_coordenado(points, weights, x_inicial)\n",
        "  print(\"DESCENSO COORDENADO:\", sol_c, f\"en {time_c:.4f}s\", f\"({iter_c} iteraciones)\")\n",
        "  sol_d, iter_d, time_d = direccion_de_descenso(points, weights, x_inicial, max_iter=100)\n",
        "  print(\"DIRECCION DE DESCENSO \", sol_d, f\"en {time_d:.4f}s\", f\"({iter_d} iteraciones)\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los resultados para las seis instancias se muestran en la siguiente tabla. En cada caso se indica cu√°ntas iteraciones necesit√≥ cada m√©todo y cu√°nto tard√≥ en ejecutarse. Como todos los m√©todos llegaron a soluciones pr√°cticamente iguales, no se incluye el valor exacto de la funci√≥n objetivo.\n"
      ],
      "metadata": {
        "id": "H6EKL6t6MGw-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Instancia | M√©todo               | Iteraciones | Tiempo (s) |\n",
        "| --------- | -------------------- | ----------- | ---------- |\n",
        "| **1**     | Weiszfeld            | 31          | 6.5003     |\n",
        "|           | Weiszfeld modificado | 36          | 0.0382     |\n",
        "|           | Desc. coordenado     | 5           | 19.5100    |\n",
        "|           | Dir. descenso        | 100 (m√°x)   | 218.0915   |\n",
        "| **2**     | Weiszfeld            | 20          | 4.7101     |\n",
        "|           | Weiszfeld modificado | 24          | 0.0252     |\n",
        "|           | Desc. coordenado     | 3           | 13.6725    |\n",
        "|           | Dir. descenso        | 100 (m√°x)   | 252.0964   |\n",
        "| **3**     | Weiszfeld            | 0           | 0.1303     |\n",
        "|           | Weiszfeld modificado | 0           | 0.0030     |\n",
        "|           | Desc. coordenado     | 1           | 4.8612     |\n",
        "|           | Dir. descenso        | 100 (m√°x)   | 531.2828   |\n",
        "| **4**     | Weiszfeld            | 20          | 3.5084     |\n",
        "|           | Weiszfeld modificado | 24          | 0.0259     |\n",
        "|           | Desc. coordenado     | 4           | 20.3151    |\n",
        "|           | Dir. descenso        | 100 (m√°x)   | 247.9203   |\n",
        "| **5**     | Weiszfeld            | 69          | 17.9941    |\n",
        "|           | Weiszfeld modificado | 70          | 0.0899     |\n",
        "|           | Desc. coordenado     | 2           | 11.4947    |\n",
        "|           | Dir. descenso        | 100 (m√°x)   | 395.8716   |\n",
        "| **6**     | Weiszfeld            | 3           | 0.8483     |\n",
        "|           | Weiszfeld modificado | 6           | 0.0132     |\n",
        "|           | Desc. coordenado     | 2           | 20.8391    |\n",
        "|           | Dir. descenso        | 100 (m√°x)   | 383.9023   |\n"
      ],
      "metadata": {
        "id": "dUxqHpQH4Eol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aunque todos llegan a soluciones similares, no todos lo hacen con la misma eficiencia ni estabilidad.\n",
        "\n",
        "El **algoritmo de Weiszfeld (original)** fue bastante r√°pido en la mayor√≠a de los casos, pero mostr√≥ algunas limitaciones. En particular, cuando la soluci√≥n coincide exactamente con uno de los puntos (como en la instancia 3), el algoritmo se detiene enseguida y puede no dar la mejor respuesta si no est√° bien tratado ese caso.\n",
        "\n",
        "La versi√≥n **modificada de Weiszfeld**, en cambio, result√≥ ser la m√°s confiable y r√°pida en todos los experimentos. Siempre encontr√≥ la soluci√≥n en pocos pasos y en tiempos muy bajos, incluso en instancias grandes o en espacios m√°s complejos (como la instancia 6 en cinco dimensiones). Adem√°s, resolvi√≥ correctamente casos donde el algoritmo original pod√≠a fallar. Por eso, es el m√©todo que m√°s conviene usar en la pr√°ctica.\n",
        "\n",
        "Es importante observar el resultado de la instancia 5 (todos los puntos alineados), donde obtuvimos un mejor tiempo en el algoritmo de descenso coordenado que en el weiszfeld sin modificar. Esto se debe a que Weiszfeld recalcula todas las distancias y necesita formar la media reponderada (calcular x_k+1), mientras que el metodo de descenso coordenado solo necesita operar sobre la unica coordenada relevante, logrando una convergencia mas rapida debido a las pocas evaluaciones unidimensionales que debe hacer\n",
        "\n",
        "El **m√©todo de descenso coordenado** tambi√©n funcion√≥ bien. Aunque tarda un poco m√°s que Weiszfeld modificado, siempre llega a la soluci√≥n con pocas iteraciones. Su mayor tiempo se debe a que en cada paso hace una b√∫squeda unidimensional bastante precisa. Si bien no es el m√°s r√°pido, es bastante estable y consistente, y puede ser una buena alternativa si se quiere evitar usar derivadas.\n",
        ".\n",
        "\n",
        "Por otro lado, el **m√©todo de direcci√≥n de descenso** (basado en subgradientes) fue el que m√°s problemas present√≥. En todas las instancias lleg√≥ al m√°ximo de iteraciones permitidas sin cumplir el criterio de parada, lo que muestra que no logr√≥ converger del todo. Adem√°s, sus tiempos fueron much√≠simo m√°s altos que los del resto (en algunos casos tard√≥ varios minutos). Aunque te√≥ricamente v√°lido, no es una buena opci√≥n pr√°ctica para este tipo de problema, sobre todo cuando los datos son grandes o hay muchas dimensiones.\n",
        "\n"
      ],
      "metadata": {
        "id": "9cFsUHwuJy5i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En **conclusi√≥n**, los resultados muestran que cada m√©todo tiene ventajas y limitaciones seg√∫n el caso. El Weiszfeld modificado fue el m√°s r√°pido y estable, siendo claramente el m√°s adecuado para aplicar en la pr√°ctica. El descenso coordenado tambi√©n cumpli√≥ bien, aunque tarda un poco m√°s, pero es una opci√≥n s√≥lida. Por otro lado, el m√©todo de direcci√≥n de descenso present√≥ varias dificultades y no result√≥ confiable en muchos casos, por lo que no se recomienda para este problema en su forma actual. En definitiva, elegir el m√©todo correcto depende de las caracter√≠sticas espec√≠ficas del problema y de los recursos disponibles."
      ],
      "metadata": {
        "id": "GseBomJbQeYJ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}